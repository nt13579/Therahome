{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import yaml\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "import os.path\n",
    "from deeplabcut.pose_estimation_tensorflow.nnet import predict\n",
    "from deeplabcut.pose_estimation_tensorflow.config import load_config\n",
    "from deeplabcut.pose_estimation_tensorflow.dataset.pose_dataset import data_to_input\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from deeplabcut.utils import auxiliaryfunctions\n",
    "from skimage.util import img_as_ubyte\n",
    "import numpy as np\n",
    "from queue import Queue \n",
    "import StreamHandler as st\n",
    "import deeplabcut as dlc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('TKAgg')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "from IPython.display import HTML\n",
    "def View(df):\n",
    "    css = \"\"\"<style>\n",
    "    table { border-collapse: collapse; border: 3px solid #eee; }\n",
    "    table tr th:first-child { background-color: #eeeeee; color: #333; font-weight: bold }\n",
    "    table thead th { background-color: #eee; color: #000; }\n",
    "    tr, th, td { border: 1px solid #ccc; border-width: 1px 0 0 1px; border-collapse: collapse;\n",
    "    padding: 3px; font-family: monospace; font-size: 10px }</style>\n",
    "    \"\"\"\n",
    "    s  = '<script type=\"text/Javascript\">'\n",
    "    s += 'var win = window.open(\"\", \"Title\", \"toolbar=no, location=no, directories=no, status=no, menubar=no, scrollbars=yes, resizable=yes, width=780, height=200, top=\"+(screen.height-400)+\", left=\"+(screen.width-840));'\n",
    "    s += 'win.document.body.innerHTML = \\'' + (df.to_html() + css).replace(\"\\n\",'\\\\') + '\\';'\n",
    "    s += '</script>'\n",
    "    return(HTML(s+css))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vid_dir = '/home/nickt/Therahome/Videos/Training/'\n",
    "main_dir = '/home/nickt/Therahome/'\n",
    "pcf = '/home/nickt/Therahome/Therahome-Nick-2021-05-12/config.yaml'\n",
    "\n",
    "os.chdir(main_dir)\n",
    "vid_dir = os.path.join(main_dir, 'Videos/Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = st.StreamHandler([2], classify_behavior=True, \n",
    "                          behavior_model_path=os.path.join(main_dir, 'SVM_BasicMovement.sav'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nickt/Therahome/Therahome-Nick-2021-05-12/dlc-models/iteration-0/TherahomeMay12-trainset95shuffle1/test/pose_cfg.yaml\n",
      "Using snapshot-810000 for model /home/nickt/Therahome/Therahome-Nick-2021-05-12/dlc-models/iteration-0/TherahomeMay12-trainset95shuffle1\n",
      "Initializing MobileNet\n",
      "INFO:tensorflow:Restoring parameters from /home/nickt/Therahome/Therahome-Nick-2021-05-12/dlc-models/iteration-0/TherahomeMay12-trainset95shuffle1/train/snapshot-810000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/nickt/Therahome/Therahome-Nick-2021-05-12/dlc-models/iteration-0/TherahomeMay12-trainset95shuffle1/train/snapshot-810000\n",
      "/home/nickt/Therahome/StreamHandler.py:589: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  tmpcfg = yaml.load(config)\n",
      "/home/nickt/Therahome/StreamHandler.py:591: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  tmpcfg = yaml.load(stream)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.])]###STOPPING###\n",
      "Stopping\n"
     ]
    }
   ],
   "source": [
    "stream.beginCapture(pcf ,labelVideo=True, shuffle =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [os.path.join(vid_dir, file) for file in os.listdir(vid_dir) if file.endswith('h5')]\n",
    "ids = {'Contracted': 1, \n",
    "       'Straight': 0, \n",
    "       'Extended': 2}\n",
    "\n",
    "y = np.empty(0)\n",
    "x = []\n",
    "for file in files:\n",
    "    value = [ids[val] for val in ids.keys() if val in file][0]\n",
    "    data = pd.read_hdf(file)\n",
    "    numel = len(data)\n",
    "    y = np.concatenate((y, np.ones(numel) * value), axis = 0)\n",
    "    if len(x) == 0:\n",
    "        x = data\n",
    "    else:\n",
    "        x = np.concatenate((x, data), axis=0)\n",
    "\n",
    "np.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(input_data, output, count = 3, print_loop=True, print_mean = True, get_meta = False, get_model = False):\n",
    "    scores = []\n",
    "    meta = {}\n",
    "    for i in range(count):\n",
    "        \n",
    "        \n",
    "        #x_train, x_test, y_train, y_test = train_test_split(input_data, output, test_size = .3)\n",
    "        \n",
    "        count = len(output)\n",
    "        random = np.random.rand(count)\n",
    "        tmpidx = np.linspace(0,count-1,count, dtype = int)\n",
    "        idx = tmpidx[np.argsort(random)]\n",
    "        split_prop = .3 #test set percentage\n",
    "        split_idx = int(len(idx) * split_prop)\n",
    "\n",
    "        test_idx = idx[0:split_idx]\n",
    "        train_idx = idx[split_idx:]\n",
    "        x_test = input_data[test_idx]\n",
    "        x_train = input_data[train_idx]\n",
    "        print(len(x_test), len(x_train))\n",
    "        y_test = output[test_idx]\n",
    "        y_train = output[train_idx]\n",
    "        \n",
    "        \n",
    "        clf = svm.SVC(kernel='linear')\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        y = clf.decision_function(x_test)\n",
    "        w_norm = np.linalg.norm(clf.coef_)\n",
    "        dist = y / w_norm\n",
    "        \n",
    "        if print_loop:\n",
    "            print(\"Accuracy {}:\".format(i), metrics.accuracy_score(y_test, y_pred))\n",
    "        tmp_meta = {}\n",
    "        if get_meta or get_model:\n",
    "            tmp_meta['x_train'] = x_train\n",
    "            tmp_meta['y_train'] = y_train\n",
    "            tmp_meta['x_test'] = x_test\n",
    "            tmp_meta['y_test'] = y_test\n",
    "            tmp_meta['y_pred'] = y_pred\n",
    "            tmp_meta['score'] = np.mean(scores)\n",
    "            tmp_meta['dist'] = dist\n",
    "            tmp_meta['split_idx'] = split_idx\n",
    "            tmp_meta['test_idx'] = test_idx\n",
    "            tmp_meta['train_idx'] = train_idx\n",
    "        meta[str(i)] = tmp_meta\n",
    "    if print_mean:\n",
    "        print(\"Mean Accuracy\", np.mean(scores))\n",
    "    if get_model:\n",
    "        return scores, meta, clf\n",
    "    elif get_meta:\n",
    "        return scores, meta\n",
    "    else:\n",
    "        return scores\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317 742\n",
      "Accuracy 0: 0.9968454258675079\n",
      "Mean Accuracy 0.9968454258675079\n"
     ]
    }
   ],
   "source": [
    "s, meta, clf = test_model(x, y, 1, get_model=True)\n",
    "filename = os.path.join(main_dir, 'SVM_BasicMovement.sav')\n",
    "pickle.dump(clf, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.4 µs ± 12.3 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "clf.predict(x[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1, 2, 3]'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "str(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(meta['0']['x_train'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'b'\n",
    "not a == None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nickt/Therahome/Therahome-Nick-2021-05-12/dlc-models/iteration-0/TherahomeMay12-trainset95shuffle1/test/pose_cfg.yaml\n",
      "Using snapshot-810000 for model /home/nickt/Therahome/Therahome-Nick-2021-05-12/dlc-models/iteration-0/TherahomeMay12-trainset95shuffle1\n",
      "Initializing MobileNet\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = [os.path.join(train_vid_dir, vid) for vid in os.listdir(train_vid_dir) if vid.endswith('avi')]\n",
    "\n",
    "project_name = 'Therahome'\n",
    "experimenter = 'Nick'\n",
    "project_created = len([file for file in os.listdir(main_dir) if file.startswith('{}-{}'.format(project_name, experimenter))]) != 0\n",
    "\n",
    "if not project_created:\n",
    "    dlc.create_new_project(project_name, experimenter, videos = vids, copy_videos='True', working_directory=main_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nickt/Therahome/Videos/Training/ClosedHand_Extended.avi',\n",
       " '/home/nickt/Therahome/Videos/Training/ClosedHand_Contracted.avi',\n",
       " '/home/nickt/Therahome/Videos/Training/ClosedHand_Straight.avi']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.extract_frames(pcf, algo='uniform' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.label_frames(pcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.create_training_dataset(pcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.train_network(pcf, displayiters=10000, saveiters=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc.evaluate_network(pcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-810000 for model /home/nickt/Therahome/Therahome-Nick-2021-05-12/dlc-models/iteration-0/TherahomeMay12-trainset95shuffle1\n",
      "Initializing MobileNet\n",
      "INFO:tensorflow:Restoring parameters from /home/nickt/Therahome/Therahome-Nick-2021-05-12/dlc-models/iteration-0/TherahomeMay12-trainset95shuffle1/train/snapshot-810000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/nickt/Therahome/Therahome-Nick-2021-05-12/dlc-models/iteration-0/TherahomeMay12-trainset95shuffle1/train/snapshot-810000\n",
      "  0%|          | 0/424 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/nickt/Therahome/Videos/Training/ClosedHand_Extended.avi\n",
      "Loading  /home/nickt/Therahome/Videos/Training/ClosedHand_Extended.avi\n",
      "Duration of video [s]:  14.13 , recorded with  30.0 fps!\n",
      "Overall # of frames:  424  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "430it [00:11, 53.27it/s]                         \n",
      "  0%|          | 0/295 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  424\n",
      "Saving results in /home/nickt/Therahome/Videos/Training...\n",
      "Starting to analyze %  /home/nickt/Therahome/Videos/Training/ClosedHand_Contracted.avi\n",
      "Loading  /home/nickt/Therahome/Videos/Training/ClosedHand_Contracted.avi\n",
      "Duration of video [s]:  9.83 , recorded with  30.0 fps!\n",
      "Overall # of frames:  295  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [00:05, 50.83it/s]                         \n",
      "  0%|          | 0/340 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  295\n",
      "Saving results in /home/nickt/Therahome/Videos/Training...\n",
      "Starting to analyze %  /home/nickt/Therahome/Videos/Training/ClosedHand_Straight.avi\n",
      "Loading  /home/nickt/Therahome/Videos/Training/ClosedHand_Straight.avi\n",
      "Duration of video [s]:  11.33 , recorded with  30.0 fps!\n",
      "Overall # of frames:  340  found with (before cropping) frame dimensions:  640 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [00:07, 45.44it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  340\n",
      "Saving results in /home/nickt/Therahome/Videos/Training...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_mobnet_100_TherahomeMay12shuffle1_810000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.analyze_videos(pcf, vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 15/424 [00:00<00:02, 139.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/nickt/Therahome/Videos/Training ['/home/nickt/Therahome/Videos/Training/ClosedHand_Extended.avi', '/home/nickt/Therahome/Videos/Training/ClosedHand_Contracted.avi', '/home/nickt/Therahome/Videos/Training/ClosedHand_Straight.avi']\n",
      "Loading  /home/nickt/Therahome/Videos/Training/ClosedHand_Extended.avi and data.\n",
      "424\n",
      "Duration of video [s]:  14.13 , recorded with  30.0 fps!\n",
      "Overall # of frames:  424 with cropped frame dimensions:  640 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 424/424 [00:02<00:00, 166.43it/s]\n",
      "  4%|▍         | 13/295 [00:00<00:02, 125.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/nickt/Therahome/Videos/Training ['/home/nickt/Therahome/Videos/Training/ClosedHand_Extended.avi', '/home/nickt/Therahome/Videos/Training/ClosedHand_Contracted.avi', '/home/nickt/Therahome/Videos/Training/ClosedHand_Straight.avi']\n",
      "Loading  /home/nickt/Therahome/Videos/Training/ClosedHand_Contracted.avi and data.\n",
      "295\n",
      "Duration of video [s]:  9.83 , recorded with  30.0 fps!\n",
      "Overall # of frames:  295 with cropped frame dimensions:  640 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [00:02<00:00, 126.69it/s]\n",
      "  3%|▎         | 11/340 [00:00<00:03, 101.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/nickt/Therahome/Videos/Training ['/home/nickt/Therahome/Videos/Training/ClosedHand_Extended.avi', '/home/nickt/Therahome/Videos/Training/ClosedHand_Contracted.avi', '/home/nickt/Therahome/Videos/Training/ClosedHand_Straight.avi']\n",
      "Loading  /home/nickt/Therahome/Videos/Training/ClosedHand_Straight.avi and data.\n",
      "340\n",
      "Duration of video [s]:  11.33 , recorded with  30.0 fps!\n",
      "Overall # of frames:  340 with cropped frame dimensions:  640 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [00:02<00:00, 146.49it/s]\n"
     ]
    }
   ],
   "source": [
    "dlc.create_labeled_video(pcf, vids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlc)\n\n",
   "language": "python",
   "name": "dlc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
